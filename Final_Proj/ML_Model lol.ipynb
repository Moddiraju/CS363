{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1ef491",
   "metadata": {},
   "source": [
    "# ML Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b997a63",
   "metadata": {},
   "source": [
    "**Headers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b18f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "import scipy as scp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d022e1",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3324db01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Intake Time</th>\n",
       "      <th>Found Location</th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Animal Type</th>\n",
       "      <th>Sex upon Intake</th>\n",
       "      <th>Age upon Intake</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>Outcome Time</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Outcome Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A706918</td>\n",
       "      <td>Belle</td>\n",
       "      <td>07/05/2015 12:59:00 PM</td>\n",
       "      <td>9409 Bluegrass Dr in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>8 years</td>\n",
       "      <td>English Springer Spaniel</td>\n",
       "      <td>White/Liver</td>\n",
       "      <td>07/05/2015 03:13:00 PM</td>\n",
       "      <td>07/05/2007</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A724273</td>\n",
       "      <td>Runster</td>\n",
       "      <td>04/14/2016 06:43:00 PM</td>\n",
       "      <td>2818 Palomino Trail in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>11 months</td>\n",
       "      <td>Basenji Mix</td>\n",
       "      <td>Sable/White</td>\n",
       "      <td>04/21/2016 05:17:00 PM</td>\n",
       "      <td>04/17/2015</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A857105</td>\n",
       "      <td>Johnny Ringo</td>\n",
       "      <td>05/12/2022 12:23:00 AM</td>\n",
       "      <td>4404 Sarasota Drive in Austin (TX)</td>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Domestic Shorthair</td>\n",
       "      <td>Orange Tabby</td>\n",
       "      <td>05/12/2022 02:35:00 PM</td>\n",
       "      <td>05/12/2020</td>\n",
       "      <td>Transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A743852</td>\n",
       "      <td>Odin</td>\n",
       "      <td>02/18/2017 12:46:00 PM</td>\n",
       "      <td>Austin (TX)</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Labrador Retriever Mix</td>\n",
       "      <td>Chocolate</td>\n",
       "      <td>02/21/2017 05:44:00 PM</td>\n",
       "      <td>02/18/2015</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A635072</td>\n",
       "      <td>Beowulf</td>\n",
       "      <td>04/16/2019 09:53:00 AM</td>\n",
       "      <td>415 East Mary Street in Austin (TX)</td>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>6 years</td>\n",
       "      <td>Great Dane Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>04/18/2019 01:45:00 PM</td>\n",
       "      <td>06/03/2012</td>\n",
       "      <td>Return to Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id          Name             Intake Time  \\\n",
       "0  A706918         Belle  07/05/2015 12:59:00 PM   \n",
       "1  A724273       Runster  04/14/2016 06:43:00 PM   \n",
       "2  A857105  Johnny Ringo  05/12/2022 12:23:00 AM   \n",
       "3  A743852          Odin  02/18/2017 12:46:00 PM   \n",
       "4  A635072       Beowulf  04/16/2019 09:53:00 AM   \n",
       "\n",
       "                        Found Location      Intake Type Intake Condition  \\\n",
       "0     9409 Bluegrass Dr in Austin (TX)            Stray           Normal   \n",
       "1   2818 Palomino Trail in Austin (TX)            Stray           Normal   \n",
       "2   4404 Sarasota Drive in Austin (TX)    Public Assist           Normal   \n",
       "3                          Austin (TX)  Owner Surrender           Normal   \n",
       "4  415 East Mary Street in Austin (TX)    Public Assist           Normal   \n",
       "\n",
       "  Animal Type Sex upon Intake Age upon Intake                     Breed  \\\n",
       "0         Dog   Spayed Female         8 years  English Springer Spaniel   \n",
       "1         Dog     Intact Male       11 months               Basenji Mix   \n",
       "2         Cat   Neutered Male         2 years        Domestic Shorthair   \n",
       "3         Dog   Neutered Male         2 years    Labrador Retriever Mix   \n",
       "4         Dog   Neutered Male         6 years            Great Dane Mix   \n",
       "\n",
       "          Color            Outcome Time Date of Birth     Outcome Type  \n",
       "0   White/Liver  07/05/2015 03:13:00 PM    07/05/2007  Return to Owner  \n",
       "1   Sable/White  04/21/2016 05:17:00 PM    04/17/2015  Return to Owner  \n",
       "2  Orange Tabby  05/12/2022 02:35:00 PM    05/12/2020         Transfer  \n",
       "3     Chocolate  02/21/2017 05:44:00 PM    02/18/2015  Return to Owner  \n",
       "4         Black  04/18/2019 01:45:00 PM    06/03/2012  Return to Owner  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"train.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560435a",
   "metadata": {},
   "source": [
    "## Section A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c914d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# String parser\n",
    "\n",
    "def parse_age(age_str):\n",
    "    if pd.isna(age_str):\n",
    "        return pd.NaT  # or np.nan\n",
    "    num, unit = age_str.split()\n",
    "    num = int(num)\n",
    "    if unit in [\"day\", \"days\"]:\n",
    "        return pd.Timedelta(days=num)\n",
    "    elif unit in [\"week\", \"weeks\"]:\n",
    "        return pd.Timedelta(days=num * 7) # approx for a week\n",
    "    elif unit in [\"month\", \"months\"]:\n",
    "        return pd.Timedelta(days=num * 30)  # Approximate 1 month = 30 days\n",
    "    elif unit in [\"year\", \"years\"]:\n",
    "        return pd.Timedelta(days=num * 365)  # Approximate 1 year = 365 days\n",
    "    else:\n",
    "        return pd.NaT\n",
    "\n",
    "# Convert to datetime objects \n",
    "raw_data[\"Intake_DateTime\"] = pd.to_datetime(raw_data[\"Intake Time\"], format=\"%m/%d/%Y %I:%M:%S %p\", errors='coerce')\n",
    "raw_data[\"Age_DateTime\"] = raw_data[\"Age upon Intake\"].apply(parse_age)\n",
    "raw_data[\"DOB_DateTime\"] = pd.to_datetime(raw_data[\"Date of Birth\"], format=\"%m/%d/%Y\", errors='coerce')\n",
    " \n",
    "# check and clean age_time\n",
    "missing_row = raw_data[raw_data[\"Age_DateTime\"].isna()]\n",
    "raw_data = raw_data[raw_data[\"Age_DateTime\"].notna()]\n",
    "data = raw_data\n",
    "missing_intakes = data[\"Intake_DateTime\"].isnull().sum()\n",
    "missing_DOBS = data[\"DOB_DateTime\"].isnull().sum()\n",
    "data[\"Age_in_Days\"] = data[\"Age_DateTime\"].dt.days ## numeric value for training\n",
    "\n",
    "## no missing values\n",
    "print(missing_intakes)\n",
    "print(missing_DOBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a5720",
   "metadata": {},
   "source": [
    "## Section B (Artifact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea7cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Animal Type</th>\n",
       "      <th>Sex upon Intake</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Intake_DateTime</th>\n",
       "      <th>Age_DateTime</th>\n",
       "      <th>DOB_DateTime</th>\n",
       "      <th>Age_in_Days</th>\n",
       "      <th>Outcome_DateTime</th>\n",
       "      <th>Time_spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>English Springer Spaniel</td>\n",
       "      <td>White/Liver</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>2015-07-05 12:59:00</td>\n",
       "      <td>2920 days</td>\n",
       "      <td>2007-07-05</td>\n",
       "      <td>2920</td>\n",
       "      <td>2015-07-05 15:13:00</td>\n",
       "      <td>8040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>Basenji Mix</td>\n",
       "      <td>Sable/White</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>2016-04-14 18:43:00</td>\n",
       "      <td>330 days</td>\n",
       "      <td>2015-04-17</td>\n",
       "      <td>330</td>\n",
       "      <td>2016-04-21 17:17:00</td>\n",
       "      <td>599640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Domestic Shorthair</td>\n",
       "      <td>Orange Tabby</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>2022-05-12 00:23:00</td>\n",
       "      <td>730 days</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>730</td>\n",
       "      <td>2022-05-12 14:35:00</td>\n",
       "      <td>51120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Labrador Retriever Mix</td>\n",
       "      <td>Chocolate</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>2017-02-18 12:46:00</td>\n",
       "      <td>730 days</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>730</td>\n",
       "      <td>2017-02-21 17:44:00</td>\n",
       "      <td>277080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public Assist</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Great Dane Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>2019-04-16 09:53:00</td>\n",
       "      <td>2190 days</td>\n",
       "      <td>2012-06-03</td>\n",
       "      <td>2190</td>\n",
       "      <td>2019-04-18 13:45:00</td>\n",
       "      <td>186720.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Intake Type Intake Condition Animal Type Sex upon Intake  \\\n",
       "0            Stray           Normal         Dog   Spayed Female   \n",
       "1            Stray           Normal         Dog     Intact Male   \n",
       "2    Public Assist           Normal         Cat   Neutered Male   \n",
       "3  Owner Surrender           Normal         Dog   Neutered Male   \n",
       "4    Public Assist           Normal         Dog   Neutered Male   \n",
       "\n",
       "                      Breed         Color     Outcome Type  \\\n",
       "0  English Springer Spaniel   White/Liver  Return to Owner   \n",
       "1               Basenji Mix   Sable/White  Return to Owner   \n",
       "2        Domestic Shorthair  Orange Tabby         Transfer   \n",
       "3    Labrador Retriever Mix     Chocolate  Return to Owner   \n",
       "4            Great Dane Mix         Black  Return to Owner   \n",
       "\n",
       "      Intake_DateTime Age_DateTime DOB_DateTime  Age_in_Days  \\\n",
       "0 2015-07-05 12:59:00    2920 days   2007-07-05         2920   \n",
       "1 2016-04-14 18:43:00     330 days   2015-04-17          330   \n",
       "2 2022-05-12 00:23:00     730 days   2020-05-12          730   \n",
       "3 2017-02-18 12:46:00     730 days   2015-02-18          730   \n",
       "4 2019-04-16 09:53:00    2190 days   2012-06-03         2190   \n",
       "\n",
       "     Outcome_DateTime  Time_spent  \n",
       "0 2015-07-05 15:13:00      8040.0  \n",
       "1 2016-04-21 17:17:00    599640.0  \n",
       "2 2022-05-12 14:35:00     51120.0  \n",
       "3 2017-02-21 17:44:00    277080.0  \n",
       "4 2019-04-18 13:45:00    186720.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Outcome_DateTime\"] = pd.to_datetime(data[\"Outcome Time\"], format=\"%m/%d/%Y %I:%M:%S %p\", errors='coerce')\n",
    "data[\"Time_spent\"] = (data[\"Outcome_DateTime\"] - data[\"Intake_DateTime\"]).dt.total_seconds() ## This column is an artifact and has been removed in the below preprocess()\n",
    "data = data.drop(columns=[\"Id\", \"Name\", \"Intake Time\", \"Found Location\", \"Age upon Intake\", \"Outcome Time\", \"Date of Birth\"])\n",
    "data.head()\n",
    "\n",
    "## First set of cleaning done, these columns were replaced with calculable values or removed (name probably does not affect outcome)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fb86c",
   "metadata": {},
   "source": [
    "## Section C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c537e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440\n",
      "568\n",
      "6\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Im looking to see what else I can erase here simply/how I should encode these categorical\n",
    "\n",
    "\n",
    "print(data[\"Breed\"].nunique()) # frequency\n",
    "print(data[\"Color\"].nunique()) #\n",
    "print(data[\"Intake Type\"].nunique())\n",
    "print(data[\"Intake Condition\"].nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b348568",
   "metadata": {},
   "source": [
    "## Section D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa81790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Outcome Type     Intake_DateTime Age_DateTime DOB_DateTime  Age_in_Days  \\\n",
      "0  Return to Owner 2015-07-05 12:59:00    2920 days   2007-07-05         2920   \n",
      "1  Return to Owner 2016-04-14 18:43:00     330 days   2015-04-17          330   \n",
      "2         Transfer 2022-05-12 00:23:00     730 days   2020-05-12          730   \n",
      "3  Return to Owner 2017-02-18 12:46:00     730 days   2015-02-18          730   \n",
      "4  Return to Owner 2019-04-16 09:53:00    2190 days   2012-06-03         2190   \n",
      "\n",
      "     Outcome_DateTime  Time_spent  Color_Agouti  Color_Agouti/Brown Tabby  \\\n",
      "0 2015-07-05 15:13:00      8040.0         False                     False   \n",
      "1 2016-04-21 17:17:00    599640.0         False                     False   \n",
      "2 2022-05-12 14:35:00     51120.0         False                     False   \n",
      "3 2017-02-21 17:44:00    277080.0         False                     False   \n",
      "4 2019-04-18 13:45:00    186720.0         False                     False   \n",
      "\n",
      "   Color_Agouti/Cream  ...  Intake Condition_Parvo  Intake Condition_Pregnant  \\\n",
      "0               False  ...                   False                      False   \n",
      "1               False  ...                   False                      False   \n",
      "2               False  ...                   False                      False   \n",
      "3               False  ...                   False                      False   \n",
      "4               False  ...                   False                      False   \n",
      "\n",
      "   Intake Condition_Sick  Intake Condition_Space  Intake Condition_Unknown  \\\n",
      "0                  False                   False                     False   \n",
      "1                  False                   False                     False   \n",
      "2                  False                   False                     False   \n",
      "3                  False                   False                     False   \n",
      "4                  False                   False                     False   \n",
      "\n",
      "   Sex upon Intake_Intact Female  Sex upon Intake_Intact Male  \\\n",
      "0                          False                        False   \n",
      "1                          False                         True   \n",
      "2                          False                        False   \n",
      "3                          False                        False   \n",
      "4                          False                        False   \n",
      "\n",
      "   Sex upon Intake_Neutered Male  Sex upon Intake_Spayed Female  \\\n",
      "0                          False                           True   \n",
      "1                          False                          False   \n",
      "2                           True                          False   \n",
      "3                           True                          False   \n",
      "4                           True                          False   \n",
      "\n",
      "   Sex upon Intake_Unknown  \n",
      "0                    False  \n",
      "1                    False  \n",
      "2                    False  \n",
      "3                    False  \n",
      "4                    False  \n",
      "\n",
      "[5 rows x 3047 columns]\n",
      "(111156, 3047)\n"
     ]
    }
   ],
   "source": [
    "# Could OHE everything, then PCA\n",
    "OHE_data = pd.get_dummies(data, columns=['Color', 'Breed', \"Animal Type\", \"Intake Type\", \"Intake Condition\", \"Sex upon Intake\"])\n",
    "print(OHE_data.head())\n",
    "print(OHE_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec22644",
   "metadata": {},
   "source": [
    "## Section E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a4f224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111156, 3063)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make something useful from the days of intake\n",
    "\n",
    "OHE_data[\"Intake_Minute\"] = OHE_data[\"Intake_DateTime\"].dt.minute\n",
    "OHE_data['Intake_Hour'] = OHE_data['Intake_DateTime'].dt.hour\n",
    "OHE_data['Intake_Weekday'] = OHE_data['Intake_DateTime'].dt.weekday  # Monday=0\n",
    "OHE_data['Intake_Month'] = OHE_data['Intake_DateTime'].dt.month\n",
    "OHE_data['Intake_Year'] = OHE_data['Intake_DateTime'].dt.year\n",
    "OHE_data['Is_Weekend_Intake'] = OHE_data['Intake_Weekday'].isin([5, 6])\n",
    "\n",
    "## Make something useful from the day of outcome\n",
    "\n",
    "OHE_data[\"Outcome_Minute\"] = OHE_data[\"Outcome_DateTime\"].dt.minute\n",
    "OHE_data['Outcome_Hour'] = OHE_data['Outcome_DateTime'].dt.hour\n",
    "OHE_data['Outcome_Weekday'] = OHE_data['Outcome_DateTime'].dt.weekday  # Monday=0\n",
    "OHE_data['Outcome_Month'] = OHE_data['Outcome_DateTime'].dt.month\n",
    "OHE_data['Outcome_Year'] = OHE_data['Outcome_DateTime'].dt.year\n",
    "OHE_data['Is_Weekend_Outcome'] = OHE_data['Outcome_Weekday'].isin([5, 6])\n",
    "\n",
    "unscaled_data = OHE_data.drop(columns=[\"Outcome_DateTime\", \"Intake_DateTime\", \"Age_DateTime\", \"DOB_DateTime\"]) ## redundant columns\n",
    "\n",
    "## Cyclic encoding bc mondays are near sunday\n",
    "unscaled_data['Intake_Minute_sin'] = np.sin(2 * np.pi * OHE_data['Intake_Minute'] / 60)\n",
    "unscaled_data['Intake_Minute_cos'] = np.cos(2 * np.pi * OHE_data['Intake_Minute'] / 60)\n",
    "\n",
    "unscaled_data['Intake_Hour_sin'] = np.sin(2 * np.pi * OHE_data['Intake_Hour'] / 24)\n",
    "unscaled_data['Intake_Hour_cos'] = np.cos(2 * np.pi * OHE_data['Intake_Hour'] / 24)\n",
    "\n",
    "unscaled_data['Intake_Weekday_sin'] = np.sin(2 * np.pi * OHE_data['Intake_Weekday'] / 7)\n",
    "unscaled_data['Intake_Weekday_cos'] = np.cos(2 * np.pi * OHE_data['Intake_Weekday'] / 7)\n",
    "\n",
    "unscaled_data['Intake_Month_sin'] = np.sin(2 * np.pi * OHE_data['Intake_Month'] / 12)\n",
    "unscaled_data['Intake_Month_cos'] = np.cos(2 * np.pi * OHE_data['Intake_Month'] / 12)\n",
    "\n",
    "unscaled_data['Outcome_Minute_sin'] = np.sin(2 * np.pi * OHE_data['Outcome_Minute'] / 60)\n",
    "unscaled_data['Outcome_Minute_cos'] = np.cos(2 * np.pi * OHE_data['Outcome_Minute'] / 60)\n",
    "\n",
    "unscaled_data['Outcome_Hour_sin'] = np.sin(2 * np.pi * OHE_data['Outcome_Hour'] / 24)\n",
    "unscaled_data['Outcome_Hour_cos'] = np.cos(2 * np.pi * OHE_data['Outcome_Hour'] / 24)\n",
    "\n",
    "unscaled_data['Outcome_Weekday_sin'] = np.sin(2 * np.pi * OHE_data['Outcome_Weekday'] / 7)\n",
    "unscaled_data['Outcome_Weekday_cos'] = np.cos(2 * np.pi * OHE_data['Outcome_Weekday'] / 7)\n",
    "\n",
    "unscaled_data['Outcome_Month_sin'] = np.sin(2 * np.pi * OHE_data['Outcome_Month'] / 12)\n",
    "unscaled_data['Outcome_Month_cos'] = np.cos(2 * np.pi * OHE_data['Outcome_Month'] / 12)\n",
    "\n",
    "## drop non-cyclical\n",
    "unscaled_data.drop(columns=[\n",
    "    'Intake_Minute', 'Intake_Hour', 'Intake_Weekday', 'Intake_Month',\n",
    "    'Outcome_Minute', 'Outcome_Hour', 'Outcome_Weekday', 'Outcome_Month'\n",
    "], inplace=True)\n",
    "unscaled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c0241",
   "metadata": {},
   "source": [
    "## Section F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a54486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age_in_Days', 'Time_spent', 'Intake_Year', 'Outcome_Year',\n",
      "       'Intake_Minute_sin', 'Intake_Minute_cos', 'Intake_Hour_sin',\n",
      "       'Intake_Hour_cos', 'Intake_Weekday_sin', 'Intake_Weekday_cos',\n",
      "       'Intake_Month_sin', 'Intake_Month_cos', 'Outcome_Minute_sin',\n",
      "       'Outcome_Minute_cos', 'Outcome_Hour_sin', 'Outcome_Hour_cos',\n",
      "       'Outcome_Weekday_sin', 'Outcome_Weekday_cos', 'Outcome_Month_sin',\n",
      "       'Outcome_Month_cos'],\n",
      "      dtype='object')\n",
      "(107908, 3063)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## Numeric Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_cols = unscaled_data.select_dtypes(include=['number']).columns\n",
    "print(numeric_cols)\n",
    "\n",
    "\n",
    "unscaled_data = unscaled_data[unscaled_data['Age_in_Days'] >= 0]\n",
    "unscaled_data = unscaled_data[unscaled_data['Time_spent'] >= 0]\n",
    "\n",
    "unscaled_data[\"Age_in_Days\"].describe()\n",
    "missing = unscaled_data.isnull().sum().sum()\n",
    "print(unscaled_data.shape)\n",
    "unscaled_data.head()\n",
    "\n",
    "## scale it lol\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_unbounded = [\"Age_in_Days\", \"Time_spent\", \"Intake_Year\", \"Outcome_Year\"]\n",
    "scaled_data = unscaled_data\n",
    "scaled_data[numeric_unbounded] = scaler.fit_transform(scaled_data[numeric_unbounded])\n",
    "scaled_data.head()\n",
    "num_missing = scaled_data['Outcome Type'].isnull().sum()\n",
    "print(num_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f72f65",
   "metadata": {},
   "source": [
    "## Section G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73fd499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['Outcome Type'], dtype='object')\n",
      "Dtype counts: float32    3062\n",
      "object        1\n",
      "Name: count, dtype: int64\n",
      "Total missing values: 0\n",
      "Missing in y: 0\n",
      "X shape: (107908, 3062)\n",
      "y shape: (107908,)\n",
      "X dtype counts: float32    3062\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Separate target from features\n",
    "y = scaled_data[\"Outcome Type\"]\n",
    "X = scaled_data.drop(columns=['Outcome Type'])\n",
    "\n",
    "# Step 2: Coerce features to numeric and cast to float32\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "X = X.astype('float32')\n",
    "\n",
    "# Step 3: Reattach target to cleaned DataFrame\n",
    "final_data = X.copy()\n",
    "final_data['Outcome Type'] = y\n",
    "\n",
    "# Step 4: Optional sanity checks\n",
    "print(\"Non-numeric columns:\", final_data.select_dtypes(exclude=['number']).columns)\n",
    "print(\"Dtype counts:\", final_data.dtypes.value_counts())\n",
    "print(\"Total missing values:\", final_data.isnull().sum().sum())\n",
    "print(\"Missing in y:\", final_data['Outcome Type'].isnull().sum())\n",
    "\n",
    "# Step 5: Drop rows with missing y or missing features\n",
    "final_data = final_data.dropna()\n",
    "y = final_data['Outcome Type']\n",
    "X = final_data.drop(columns=['Outcome Type'])\n",
    "\n",
    "# Step 6: Encode y if it's categorical\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "# Now X and y are clean and ready for training\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"X dtype counts:\", X.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5e176",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514124a",
   "metadata": {},
   "source": [
    "## Section H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d08b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define parameter grid\\nparam_grid = {\\n    \\'hidden_layer_sizes\\': [\\n        (64,), (128,), (256,),\\n        (128, 64), (256, 128)\\n    ],\\n    \\'alpha\\': [1e-4, 1e-3]\\n}\\n\\n\\n# Define base model\\nmlp = MLPClassifier(\\n    max_iter=300,\\n    early_stopping=True,\\n    random_state=42\\n)\\n\\n# Set up GridSearchCV\\ngrid_search = GridSearchCV(\\n    estimator=mlp,\\n    param_grid=param_grid,\\n    scoring=\\'accuracy\\',\\n    cv=5,\\n    n_jobs=4,\\n    verbose=2\\n)\\n\\n# Fit the grid search\\ngrid_search.fit(X, y)\\n\\n# Show the best results\\nprint(\"Best parameters found:\", grid_search.best_params_)\\nprint(\"Best cross-validated accuracy:\", grid_search.best_score_)\\n\\n# Optional: View all results sorted\\ncv_results = pd.DataFrame(grid_search.cv_results_)\\ncv_results = cv_results.sort_values(\\'mean_test_score\\', ascending=False)\\nprint(cv_results[[\\'mean_test_score\\', \\'params\\']])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for best params\n",
    "\"\"\"\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (64,), (128,), (256,),\n",
    "        (128, 64), (256, 128), (256, 64), \n",
    "        (256, 128, 64)\n",
    "    ],\n",
    "    'alpha': [1e-4, 1e-3]\n",
    "}\n",
    "\n",
    "\n",
    "# Define base model\n",
    "mlp = MLPClassifier(\n",
    "    max_iter=300,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Show the best results\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Optional: View all results sorted\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results.sort_values('mean_test_score', ascending=False)\n",
    "print(cv_results[['mean_test_score', 'params']])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca40a37",
   "metadata": {},
   "source": [
    "## Full Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12b7cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_data):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "    anim_ids = raw_data[\"Id\"].copy()\n",
    "    le = None\n",
    "    if 'Name' in raw_data.columns:\n",
    "        raw_data = raw_data.drop(columns=['Name'])\n",
    "    if 'Outcome Time' in raw_data.columns:\n",
    "        raw_data = raw_data.drop(columns=['Outcome Time'])\n",
    "    if 'Outcome Type' in raw_data.columns:\n",
    "        y = raw_data['Outcome Type'].copy()\n",
    "        raw_data = raw_data.drop(columns=[\"Outcome Type\"])\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    # Module 1 — Age + Date parsing\n",
    "    def parse_age(age_str):\n",
    "        if pd.isna(age_str):\n",
    "            return pd.NaT\n",
    "        num, unit = age_str.split()\n",
    "        num = int(num)\n",
    "        if unit in [\"day\", \"days\"]:\n",
    "            return pd.Timedelta(days=num)\n",
    "        elif unit in [\"week\", \"weeks\"]:\n",
    "            return pd.Timedelta(days=num * 7)\n",
    "        elif unit in [\"month\", \"months\"]:\n",
    "            return pd.Timedelta(days=num * 30)\n",
    "        elif unit in [\"year\", \"years\"]:\n",
    "            return pd.Timedelta(days=num * 365)\n",
    "        else:\n",
    "            return pd.NaT\n",
    "\n",
    "    raw_data[\"Intake_DateTime\"] = pd.to_datetime(\n",
    "        raw_data[\"Intake Time\"], errors='coerce', infer_datetime_format=True\n",
    "    )    \n",
    "    raw_data[\"Age_DateTime\"] = raw_data[\"Age upon Intake\"].apply(parse_age)\n",
    "    raw_data[\"DOB_DateTime\"] = pd.to_datetime(raw_data[\"Date of Birth\"], format=\"%m/%d/%Y\", errors='coerce')\n",
    "\n",
    "    # Clean age\n",
    "    data = raw_data.copy()\n",
    "    data[\"Age_in_Days\"] = data[\"Age_DateTime\"].dt.days\n",
    "\n",
    "    # Module 2 — Drop irrelevant columns\n",
    "    data = data.drop(columns=[\"Id\", \"Intake Time\", \"Found Location\", \"Age upon Intake\", \"Date of Birth\"])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    OHE_data = pd.get_dummies(data, columns=['Color', 'Breed', \"Animal Type\", \"Intake Type\", \"Intake Condition\", \"Sex upon Intake\"])\n",
    "    print(OHE_data.shape)\n",
    "\n",
    "    # Module 3 — Feature Engineering from Intake Time\n",
    "    OHE_data[\"Intake_Minute\"] = OHE_data[\"Intake_DateTime\"].dt.minute\n",
    "    OHE_data['Intake_Hour'] = OHE_data['Intake_DateTime'].dt.hour\n",
    "    OHE_data['Intake_Weekday'] = OHE_data['Intake_DateTime'].dt.weekday\n",
    "    OHE_data['Intake_Month'] = OHE_data['Intake_DateTime'].dt.month\n",
    "    OHE_data['Intake_Year'] = OHE_data['Intake_DateTime'].dt.year\n",
    "    OHE_data['Is_Weekend_Intake'] = OHE_data['Intake_Weekday'].isin([5, 6])\n",
    "\n",
    "    # Drop datetimes\n",
    "    unscaled_data = OHE_data.drop(columns=[\"Intake_DateTime\", \"Age_DateTime\", \"DOB_DateTime\"])\n",
    "\n",
    "    # Cyclical encoding\n",
    "    unscaled_data['Intake_Minute_sin'] = np.sin(2 * np.pi * OHE_data['Intake_Minute'] / 60)\n",
    "    unscaled_data['Intake_Minute_cos'] = np.cos(2 * np.pi * OHE_data['Intake_Minute'] / 60)\n",
    "    unscaled_data['Intake_Hour_sin'] = np.sin(2 * np.pi * OHE_data['Intake_Hour'] / 24)\n",
    "    unscaled_data['Intake_Hour_cos'] = np.cos(2 * np.pi * OHE_data['Intake_Hour'] / 24)\n",
    "    unscaled_data['Intake_Weekday_sin'] = np.sin(2 * np.pi * OHE_data['Intake_Weekday'] / 7)\n",
    "    unscaled_data['Intake_Weekday_cos'] = np.cos(2 * np.pi * OHE_data['Intake_Weekday'] / 7)\n",
    "    unscaled_data['Intake_Month_sin'] = np.sin(2 * np.pi * OHE_data['Intake_Month'] / 12)\n",
    "    unscaled_data['Intake_Month_cos'] = np.cos(2 * np.pi * OHE_data['Intake_Month'] / 12)\n",
    "\n",
    "    unscaled_data.drop(columns=['Intake_Minute', 'Intake_Hour', 'Intake_Weekday', 'Intake_Month'], inplace=True)\n",
    "\n",
    "    # Module 4 — Numeric Scaling\n",
    "    numeric_unbounded = [\"Age_in_Days\", \"Intake_Year\"]\n",
    "    unscaled_data = unscaled_data[unscaled_data['Age_in_Days'] >= 0]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    unscaled_data[numeric_unbounded] = scaler.fit_transform(unscaled_data[numeric_unbounded])\n",
    "\n",
    "    # Final conversion\n",
    "    X = unscaled_data.apply(pd.to_numeric, errors='coerce').astype('float32')\n",
    "    print(\"X shape before dropna:\", X.shape)\n",
    "    print(\"NaNs per column:\\n\", X.isnull().sum().sort_values(ascending=False).head(10))\n",
    "    if y is not None:\n",
    "        y = y.loc[X.index]\n",
    "        y = y.dropna()\n",
    "        if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "    anim_ids = anim_ids.loc[X.index]    \n",
    "    print(\"Final shape of X:\", X.shape)\n",
    "    print(\"Total NaNs in X:\", X.isnull().sum().sum())\n",
    "    print(\"Columns with NaNs:\")\n",
    "    print(X.columns[X.isnull().any()])\n",
    "    X = X.apply(pd.to_numeric, errors='coerce').astype('float32')\n",
    "    assert X.select_dtypes(exclude=['number']).empty, \"Non-numeric columns still exist in X\"\n",
    "    assert not X.isnull().any().any(), \"X still contains NaNs\"\n",
    "    if y is not None:\n",
    "        print(\"Final y dtype:\", y.dtype)\n",
    "        print(\"Final y length:\", len(y))\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"Original test_data rows:\", len(raw_data))\n",
    "    print(\"Final X rows:\", len(X))\n",
    "    print(\"Final test_ids:\", len(anim_ids))\n",
    "    return X, anim_ids, y, le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401274b9",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf55ea8",
   "metadata": {},
   "source": [
    "## Section J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0b24954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moddi\\AppData\\Local\\Temp\\ipykernel_9120\\2215280648.py:37: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  raw_data[\"Intake_DateTime\"] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111157, 3045)\n",
      "X shape before dropna: (111152, 3052)\n",
      "NaNs per column:\n",
      " Age_in_Days                                        0\n",
      "Breed_Jack Russell Terrier/Standard Schnauzer      0\n",
      "Breed_Jack Russell Terrier/Miniature Poodle        0\n",
      "Breed_Jack Russell Terrier/Papillon                0\n",
      "Breed_Jack Russell Terrier/Pbgv                    0\n",
      "Breed_Jack Russell Terrier/Pembroke Welsh Corgi    0\n",
      "Breed_Jack Russell Terrier/Pit Bull                0\n",
      "Breed_Jack Russell Terrier/Pointer                 0\n",
      "Breed_Jack Russell Terrier/Pug                     0\n",
      "Breed_Jack Russell Terrier/Rat Terrier             0\n",
      "dtype: int64\n",
      "Final shape of X: (111152, 3052)\n",
      "Total NaNs in X: 0\n",
      "Columns with NaNs:\n",
      "Index([], dtype='object')\n",
      "Final y dtype: int32\n",
      "Final y length: 111152\n",
      "X shape: (111152, 3052)\n",
      "Original test_data rows: 111157\n",
      "Final X rows: 111152\n",
      "Final test_ids: 111152\n",
      "(111152, 3052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moddi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "final_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    alpha=0.001,\n",
    "    max_iter=300,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "training_data = pd.read_csv(\"train.csv\")\n",
    "training_y = training_data[\"Outcome Type\"]\n",
    "X_train, ids_train, y_train, le = preprocess(training_data)\n",
    "training_columns = X_train.columns\n",
    "final_clf.fit(X_train, y_train)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2e35c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id          Name             Intake Time  \\\n",
      "0  A706918         Belle  07/05/2015 12:59:00 PM   \n",
      "1  A724273       Runster  04/14/2016 06:43:00 PM   \n",
      "2  A857105  Johnny Ringo  05/12/2022 12:23:00 AM   \n",
      "3  A743852          Odin  02/18/2017 12:46:00 PM   \n",
      "4  A635072       Beowulf  04/16/2019 09:53:00 AM   \n",
      "\n",
      "                        Found Location      Intake Type Intake Condition  \\\n",
      "0     9409 Bluegrass Dr in Austin (TX)            Stray           Normal   \n",
      "1   2818 Palomino Trail in Austin (TX)            Stray           Normal   \n",
      "2   4404 Sarasota Drive in Austin (TX)    Public Assist           Normal   \n",
      "3                          Austin (TX)  Owner Surrender           Normal   \n",
      "4  415 East Mary Street in Austin (TX)    Public Assist           Normal   \n",
      "\n",
      "  Animal Type Sex upon Intake Age upon Intake                     Breed  \\\n",
      "0         Dog   Spayed Female         8 years  English Springer Spaniel   \n",
      "1         Dog     Intact Male       11 months               Basenji Mix   \n",
      "2         Cat   Neutered Male         2 years        Domestic Shorthair   \n",
      "3         Dog   Neutered Male         2 years    Labrador Retriever Mix   \n",
      "4         Dog   Neutered Male         6 years            Great Dane Mix   \n",
      "\n",
      "          Color            Outcome Time Date of Birth     Outcome Type  \n",
      "0   White/Liver  07/05/2015 03:13:00 PM    07/05/2007  Return to Owner  \n",
      "1   Sable/White  04/21/2016 05:17:00 PM    04/17/2015  Return to Owner  \n",
      "2  Orange Tabby  05/12/2022 02:35:00 PM    05/12/2020         Transfer  \n",
      "3     Chocolate  02/21/2017 05:44:00 PM    02/18/2015  Return to Owner  \n",
      "4         Black  04/18/2019 01:45:00 PM    06/03/2012  Return to Owner  \n"
     ]
    }
   ],
   "source": [
    "print(training_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94b2cb",
   "metadata": {},
   "source": [
    "## Section K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9df16456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moddi\\AppData\\Local\\Temp\\ipykernel_9120\\1902448573.py:37: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  raw_data[\"Intake_DateTime\"] = pd.to_datetime(\n",
      "C:\\Users\\moddi\\AppData\\Local\\Temp\\ipykernel_9120\\1902448573.py:37: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  raw_data[\"Intake_DateTime\"] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27791, 1684)\n",
      "X shape before dropna: (27791, 1691)\n",
      "NaNs per column:\n",
      " Age_in_Days                                       0\n",
      "Breed_Jack Russell Terrier/Chihuahua Shorthair    0\n",
      "Breed_Keeshond Mix                                0\n",
      "Breed_Kangal/Great Dane                           0\n",
      "Breed_Kangal Mix                                  0\n",
      "Breed_Jindo/Shiba Inu                             0\n",
      "Breed_Jindo/Pembroke Welsh Corgi                  0\n",
      "Breed_Jindo Mix                                   0\n",
      "Breed_Japanese Chin Mix                           0\n",
      "Breed_Japanese Bobtail Mix                        0\n",
      "dtype: int64\n",
      "Final shape of X: (27791, 1691)\n",
      "Total NaNs in X: 0\n",
      "Columns with NaNs:\n",
      "Index([], dtype='object')\n",
      "X shape: (27791, 1691)\n",
      "Original test_data rows: 27791\n",
      "Final X rows: 27791\n",
      "Final test_ids: 27791\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "X_test, test_ids, _, _ = preprocess(test_data)\n",
    "X_test = X_test.reindex(columns=training_columns, fill_value=0.0)\n",
    "\n",
    "y_pred = final_clf.predict(X_test)\n",
    "pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_ids,\n",
    "    \"Outcome Type\": pred_labels\n",
    "})\n",
    "submission.to_csv(\"submissionb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
